[
    {
        "commit_message": "design",
        "added_files": {
            "gemini-cli-proxy/plan.md": "# Gemini CLI Proxy è®¾è®¡æ–‡æ¡£\n\n## ğŸ“‹ é¡¹ç›®æ¦‚è¿°\n\n### ğŸ¯ é¡¹ç›®ç›®æ ‡\nå°†å‘½ä»¤è¡Œå·¥å…· `gemini` åŒ…è£…æˆ OpenAI å…¼å®¹çš„ HTTP API æœåŠ¡ï¼Œä½¿å…¶èƒ½å¤Ÿä¸ Cherry Studio ç­‰ OpenAI å®¢æˆ·ç«¯æ— ç¼é›†æˆã€‚\n\n### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½\n- **OpenAI API å…¼å®¹**ï¼šå®ç° `/v1/chat/completions` ç«¯ç‚¹\n- **å‘½ä»¤è¡Œé›†æˆ**ï¼šè°ƒç”¨æœ¬åœ° `gemini` å‘½ä»¤è¡Œå·¥å…·\n- **é€Ÿç‡é™åˆ¶**ï¼šæ¯åˆ†é’Ÿæœ€å¤š 60 æ¬¡è¯·æ±‚\n- **æµå¼åè®®å…¼å®¹ï¼ˆFake Streamï¼‰**ï¼šä½¿ç”¨ Server-Sent Events å°è£…ä¸€æ¬¡æ€§ç»“æœ\n- **ç°ä»£åŒ–åˆ†å‘**ï¼šé€šè¿‡ `uv`/`uvx` åˆ†å‘å’Œè¿è¡Œ\n\n### ğŸš« èŒƒå›´è¯´æ˜\næœ¬é¡¹ç›®å®šä½ä¸º **æœ¬åœ°å•æœºè¿è¡Œ** çš„å¼€æºå·¥å…·ï¼Œå‡è®¾ç”¨æˆ·å¯¹è¿è¡Œç¯å¢ƒå…·æœ‰å®Œå…¨æ§åˆ¶æƒã€‚ä¸ºä¿æŒç®€æ´ï¼Œæœ¬æ–‡æ¡£ä¸æ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼š  \n1. **å®‰å…¨ä¸é‰´æƒ**  \n2. **è¿ç»´ä¸ç›‘æ§**  \n3. **è‡ªåŠ¨åŒ–æµ‹è¯•ä¸ CI/CD**\n\n## ğŸ—ï¸ æŠ€æœ¯æ¶æ„\n\n### ğŸ“¦ æŠ€æœ¯é€‰å‹\n\n#### HTTP æ¡†æ¶ï¼šFastAPI\n**é€‰æ‹©ç†ç”±**ï¼š\n- âœ… **ç°ä»£åŒ–è®¾è®¡**ï¼šåŸºäºæ ‡å‡† Python ç±»å‹æç¤º\n- âœ… **é«˜æ€§èƒ½**ï¼šåŸºäº Starlette å’Œ Pydanticï¼Œæ€§èƒ½ä¼˜å¼‚\n- âœ… **è‡ªåŠ¨æ–‡æ¡£**ï¼šè‡ªåŠ¨ç”Ÿæˆ OpenAPI/Swagger æ–‡æ¡£\n- âœ… **AI ç”Ÿæ€åŸç”Ÿ**ï¼šPython åœ¨ AI é¢†åŸŸçš„åŸç”Ÿä¼˜åŠ¿\n- âœ… **MCP ç”Ÿæ€ååŒ**ï¼šä¸ç°æœ‰ AI å·¥å…·é“¾ä¸€è‡´\n\n#### åŒ…ç®¡ç†ï¼šUV\n**é€‰æ‹©ç†ç”±**ï¼š\n- âœ… **æè‡´é€Ÿåº¦**ï¼šRust ç¼–å†™ï¼Œæ¯” pip å¿« 10-100 å€\n- âœ… **é›¶å®‰è£…è¿è¡Œ**ï¼šuvx æä¾›ç±»ä¼¼ npx çš„ä½“éªŒ\n- âœ… **MCP ç”Ÿæ€æ ‡å‡†**ï¼šAI å¼€å‘è€…æ™®éä½¿ç”¨\n- âœ… **ç°ä»£åŒ–å·¥å…·é“¾**ï¼šé¡¹ç›®ç®¡ç†ã€ä¾èµ–è§£æä¸€ä½“åŒ–\n\n#### å…³é”®ä¾èµ–\n\n```toml\ndependencies = [\n  \"fastapi>=0.104.0\",           # HTTP æœåŠ¡å™¨æ¡†æ¶\n  \"uvicorn[standard]>=0.24.0\",  # ASGI æœåŠ¡å™¨\n  \"click>=8.0.0\",               # CLI å‚æ•°è§£æ\n  \"pydantic>=2.0.0\",            # æ•°æ®éªŒè¯\n  \"slowapi>=0.1.9\",             # é€Ÿç‡é™åˆ¶\n]\n```\n\n### ğŸ›ï¸ ç³»ç»Ÿæ¶æ„\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Command    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                 â”‚  Request    â”‚                 â”‚     Line      â”‚                 â”‚\nâ”‚ OpenAI Client   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ FastAPI Server  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Gemini CLI    â”‚\nâ”‚ (Cherry Studio) â”‚             â”‚                 â”‚               â”‚     Tool        â”‚\nâ”‚                 â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   Response  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Output     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### ğŸ“‚ é¡¹ç›®ç»“æ„\n\n```\ngemini-cli-proxy/\nâ”œâ”€â”€ src/gemini_cli_proxy/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ cli.py              # CLI å…¥å£ç‚¹\nâ”‚   â”œâ”€â”€ server.py           # FastAPI æœåŠ¡å™¨\nâ”‚   â”œâ”€â”€ gemini_client.py    # Gemini å‘½ä»¤è¡Œå®¢æˆ·ç«¯\nâ”‚   â”œâ”€â”€ openai_adapter.py   # OpenAI æ ¼å¼é€‚é…å™¨\nâ”‚   â”œâ”€â”€ models.py           # æ•°æ®æ¨¡å‹å®šä¹‰\nâ”‚   â””â”€â”€ config.py           # é…ç½®ç®¡ç†\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ unit/               # å•å…ƒæµ‹è¯•\nâ”‚   â””â”€â”€ integration/        # é›†æˆæµ‹è¯•\nâ”œâ”€â”€ pyproject.toml          # é¡¹ç›®é…ç½®\nâ”œâ”€â”€ README.md               # ä½¿ç”¨è¯´æ˜\nâ””â”€â”€ LICENSE                 # å¼€æºåè®®\n```\n\n### ğŸ”„ æ•°æ®æµè®¾è®¡\n1. **è¯·æ±‚æ¥æ”¶**ï¼šFastAPI æ¥æ”¶ OpenAI æ ¼å¼çš„ HTTP è¯·æ±‚\n2. **æ ¼å¼éªŒè¯**ï¼šPydantic è‡ªåŠ¨éªŒè¯è¯·æ±‚æ ¼å¼å’Œå‚æ•°\n3. **é€Ÿç‡æ§åˆ¶**ï¼šä¸­é—´ä»¶æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶\n4. **æ ¼å¼è½¬æ¢**ï¼šå°† OpenAI æ ¼å¼è½¬æ¢ä¸º Gemini å‘½ä»¤è¡Œå‚æ•°\n5. **å¼‚æ­¥æ‰§è¡Œ**ï¼šä½¿ç”¨ asyncio è°ƒç”¨æœ¬åœ°å‘½ä»¤è¡Œå·¥å…·\n6. **ç»“æœè§£æ**ï¼šè§£æå‘½ä»¤è¡Œè¾“å‡ºå¹¶æ ¼å¼åŒ–\n7. **æµå¼åè®®å°è£…ï¼ˆå¯é€‰ï¼‰**ï¼šæŒ‰éœ€å°†å®Œæ•´ç»“æœæ‹†åˆ†æˆå¤šæ¡ SSE äº‹ä»¶ï¼Œå®ç°å…¼å®¹ OpenAI Streaming åè®®\n8. **å“åº”è¿”å›**ï¼šåœ¨éæµå¼æ¨¡å¼ä¸‹è¿”å› OpenAI å…¼å®¹ JSONï¼›åœ¨æµå¼æ¨¡å¼ä¸‹ä»¥ `[DONE]` äº‹ä»¶ç»“å°¾\n\n### ğŸ“ å®ç°ç»†èŠ‚è¡¥å……\n- **Token ç”¨é‡**ï¼šç”±äº `gemini` CLI å·¥å…·ä¸æä¾› Token æ¶ˆè€—ä¿¡æ¯ï¼Œä¸ºä¿è¯æ•°æ®å‡†ç¡®æ€§ï¼Œæœ¬ä»£ç†æœåŠ¡çš„ API å“åº”ä¸­å°† **çœç•¥** `usage` å­—æ®µã€‚\n- **â€œå‡æµå¼â€å®ç°**ï¼šå½“è¯·æ±‚å‚æ•° `stream=true` æ—¶ï¼Œä»£ç†ä¼šå°† `gemini` CLI çš„å®Œæ•´è¾“å‡ºç»“æœ **æŒ‰è¡Œï¼ˆline-by-lineï¼‰** æ‹†åˆ†ï¼Œå¹¶å°è£…æˆç¬¦åˆ OpenAI è§„èŒƒçš„ Server-Sent Events (SSE) æµå¼è¿”å›ã€‚\n\n## ğŸ”§ æ ¸å¿ƒæ¨¡å—è®¾è®¡\n\n### 1. CLI å…¥å£æ¨¡å— (`cli.py`)\n**èŒè´£**ï¼šå‘½ä»¤è¡Œå‚æ•°è§£æå’Œåº”ç”¨å¯åŠ¨\n- ä½¿ç”¨ Click å¤„ç†å‘½ä»¤è¡Œå‚æ•°\n- åˆ›å»ºåº”ç”¨å®ä¾‹å¹¶å¯åŠ¨ uvicorn æœåŠ¡å™¨\n\n### 2. FastAPI æœåŠ¡å™¨ (`server.py`)\n**èŒè´£**ï¼šHTTP æœåŠ¡å’Œ API ç«¯ç‚¹\n- é…ç½® CORS å’Œä¸­é—´ä»¶\n- å®ç° `/v1/chat/completions` ç«¯ç‚¹\n- é›†æˆé€Ÿç‡é™åˆ¶å’Œé”™è¯¯å¤„ç†\n\n### 3. Gemini å®¢æˆ·ç«¯ (`gemini_client.py`)\n**èŒè´£**ï¼šä¸ Gemini CLI å·¥å…·äº¤äº’\n- å¼‚æ­¥æ‰§è¡Œå‘½ä»¤è¡Œå·¥å…·\n- å¤„ç†è¶…æ—¶å’Œé”™è¯¯æƒ…å†µ\n- æ”¯æŒå‡æµå¼æ‹†åˆ†ï¼ˆå¯é€‰ï¼‰\n\n### 4. OpenAI é€‚é…å™¨ (`openai_adapter.py`)\n**èŒè´£**ï¼šæ ¼å¼è½¬æ¢å’Œå…¼å®¹æ€§\n- OpenAI è¯·æ±‚æ ¼å¼ â†’ Gemini å‘½ä»¤è¡Œå‚æ•°\n- Gemini è¾“å‡º â†’ OpenAI å“åº”æ ¼å¼\n- æµå¼åè®®å°è£…ï¼ˆFake Streamï¼‰\n\n### 5. æ•°æ®æ¨¡å‹ (`models.py`)\n**èŒè´£**ï¼šè¯·æ±‚/å“åº”æ•°æ®éªŒè¯\n- Pydantic æ¨¡å‹å®šä¹‰\n- è‡ªåŠ¨æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–\n\n### 6. é…ç½®ç®¡ç† (`config.py`)\n**èŒè´£**ï¼šåº”ç”¨é…ç½®å’Œç¯å¢ƒå˜é‡\n- æœåŠ¡å™¨é…ç½®ï¼ˆç«¯å£ã€ä¸»æœºç­‰ï¼‰\n- Gemini CLI é…ç½®ï¼ˆå‘½ä»¤è·¯å¾„ã€è¶…æ—¶ç­‰ï¼‰\n- ç¯å¢ƒå˜é‡æ”¯æŒ\n\n## ğŸ“¡ API è®¾è®¡\n\n### ç«¯ç‚¹è§„èŒƒ\n\n#### `POST /v1/chat/completions`\n**è¯·æ±‚æ ¼å¼**ï¼š\n```json\n{\n  \"model\": \"gemini-pro\",\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 1000,\n  \"stream\": false\n}\n```\n\n**å“åº”æ ¼å¼**ï¼š\n```json\n{\n  \"id\": \"chatcmpl-1234567890\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gemini-pro\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! How can I help you today?\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"completion_tokens\": 20,\n    \"total_tokens\": 30\n  }\n}\n```\n\n> **æ³¨**ï¼šä¸ºä¿è¯æ•°æ®å‡†ç¡®æ€§ï¼Œç”±äº `gemini` CLI ä¸æä¾› Token ç”¨é‡ä¿¡æ¯ï¼Œå®é™…å“åº”ä¸­å°† **çœç•¥ `usage` å­—æ®µ**ã€‚\n\n#### `GET /health`\nå¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œè¿”å›æœåŠ¡çŠ¶æ€ã€‚\n\n#### `GET /v1/models`\nè¿”å›å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰å®ç°ï¼‰ã€‚\n\n## ğŸš€ éƒ¨ç½²å’Œå‘å¸ƒ\n\n### é¡¹ç›®é…ç½® (`pyproject.toml`)\n\n```toml\n[project]\nname = \"gemini-cli-proxy\"\nversion = \"1.0.0\"\ndescription = \"OpenAI-compatible API wrapper for Gemini CLI\"\nreadme = \"README.md\"\nlicense = { text = \"MIT\" }\nauthors = [\n    { name = \"Your Name\", email = \"your.email@example.com\" }\n]\nkeywords = [\"openai\", \"gemini\", \"api\", \"proxy\", \"cli\"]\nrequires-python = \">=3.8\"\ndependencies = [\n    \"fastapi>=0.104.0\",\n    \"uvicorn[standard]>=0.24.0\",\n    \"click>=8.0.0\",\n    \"pydantic>=2.0.0\",\n    \"slowapi>=0.1.9\",\n]\n\n[project.scripts]\ngemini-cli-proxy = \"gemini_cli_proxy.cli:main\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n```\n\n### å‘å¸ƒæµç¨‹\n\n1. **æœ¬åœ°å¼€å‘**\n   ```bash\n   # ä½¿ç”¨ uv å®‰è£…ä¾èµ–\n   uv sync\n   \n   # å¼€å‘æ¨¡å¼å®‰è£…\n   uv pip install -e .\n   ```\n\n2. **æ„å»ºå’Œå‘å¸ƒ**\n   ```bash\n   # æ„å»ºåˆ†å‘åŒ…\n   uv build\n   \n   # å‘å¸ƒåˆ° PyPI\n   uv publish\n   ```\n\n3. **ç”¨æˆ·å®‰è£…**\n   ```bash\n   uvx gemini-cli-proxy\n   ```\n\n## ğŸ›ï¸ é…ç½®ç®¡ç†\n\n### é…ç½®å±‚æ¬¡\n1. **å‘½ä»¤è¡Œå‚æ•°**ï¼šè¿è¡Œæ—¶æŒ‡å®š\n2. **ç¯å¢ƒå˜é‡**ï¼š`GEMINI_PROXY_*` å‰ç¼€\n3. **é…ç½®æ–‡ä»¶**ï¼š`.env` æ–‡ä»¶æ”¯æŒ\n\n### å…³é”®é…ç½®é¡¹\n- **æœåŠ¡å™¨**ï¼šç«¯å£ã€ä¸»æœºã€æ—¥å¿—çº§åˆ«\n- **Gemini CLI**ï¼šå‘½ä»¤è·¯å¾„ã€è¶…æ—¶æ—¶é—´\n- **é™åˆ¶**ï¼šé€Ÿç‡é™åˆ¶ã€è¯·æ±‚å¤§å°\n- **å¹¶å‘**ï¼šå­è¿›ç¨‹æœ€å¤§å¹¶å‘æ•°\n\n### ç¯å¢ƒå˜é‡æ”¯æŒ\n\n```bash\n# æœåŠ¡å™¨é…ç½®\nGEMINI_PROXY_HOST=127.0.0.1\nGEMINI_PROXY_PORT=7000\n\n# Gemini CLI é…ç½®\nGEMINI_PROXY_TIMEOUT=30.0\nGEMINI_PROXY_RATE_LIMIT=60\n\n# å¹¶å‘é…ç½®\nGEMINI_PROXY_MAX_CONCURRENCY=4\n\n# æ—¥å¿—é…ç½®\nGEMINI_PROXY_LOG_LEVEL=info\nGEMINI_PROXY_DEBUG=false\n```\n\n## âš™ï¸ å¹¶å‘ä¸æ€§èƒ½\n\n- ä½¿ç”¨ `asyncio.create_subprocess_exec` å¯åŠ¨ Gemini CLIï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ã€‚  \n- é€šè¿‡ `asyncio.Semaphore` æ§åˆ¶å¹¶å‘å­è¿›ç¨‹æ•°é‡ï¼Œé»˜è®¤å€¼ä¸º `min(4, CPU æ ¸å¿ƒæ•°)`ï¼Œå¯ç”±ç¯å¢ƒå˜é‡ `GEMINI_PROXY_MAX_CONCURRENCY` æˆ– `--max-concurrency` å‚æ•°è¦†ç›–ã€‚  \n- é€Ÿç‡é™åˆ¶ä¾èµ– SlowAPIï¼Œé»˜è®¤æ¯åˆ†é’Ÿ 60 æ¬¡è¯·æ±‚ï¼Œå¯é€šè¿‡ `--rate-limit` æˆ– `GEMINI_PROXY_RATE_LIMIT` ä¿®æ”¹ã€‚\n\n## ğŸ’¥ é”™è¯¯å¤„ç†è®¾è®¡\n\n| åœºæ™¯ | HTTP çŠ¶æ€ç  | OpenAI `error.type` | è¯´æ˜ |\n|------|-------------|---------------------|------|\n| è¯·æ±‚å‚æ•°æ ¡éªŒå¤±è´¥ | 400 | invalid_request_error | Pydantic æŠ¥é”™ä¿¡æ¯ |\n| è§¦å‘é€Ÿç‡é™åˆ¶ | 429 | rate_limit_error | è¿”å› `Retry-After` å¤´ |\n| CLI è¶…æ—¶æˆ–éé›¶é€€å‡º | 502 | bad_gateway | `stderr` ä½œä¸º message |\n| CLI è¢«å–æ¶ˆ / KeyboardInterrupt | 500 | internal_error | - |\n| æœªçŸ¥å¼‚å¸¸ | 500 | internal_error | å…œåº•å¤„ç† |\n\næ‰€æœ‰é”™è¯¯å“åº”å‡éµå¾ª OpenAI é”™è¯¯ JSONï¼š\n```json\n{\n  \"error\": {\n    \"message\": \"...\",\n    \"type\": \"invalid_request_error\",\n    \"param\": null,\n    \"code\": \"400\"\n  }\n}\n```\n## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹\n\n### å®‰è£…å’Œå¯åŠ¨\nç›´æ¥è¿è¡Œï¼š\n```bash\nuvx gemini-cli-proxy --port 7000\n```\n\nåœ¨é¡¹ç›®ä¸­å¯åŠ¨ï¼š\n```bash\nuv run gemini-cli-proxy --port 7000\n```\n\n### Cherry Studio é…ç½®\n1. å¯åŠ¨æœåŠ¡ï¼š`uvx gemini-cli-proxy`\n2. åœ¨ Cherry Studio è®¾ç½®ä¸­ï¼š\n   - Provider: OpenAI\n   - Base URL: `http://localhost:7000/v1`\n   - API Key: ä»»æ„å­—ç¬¦ä¸²ï¼ˆä¸éªŒè¯ï¼‰\n   - Model: `gemini-pro`\n\n### OpenAI å®¢æˆ·ç«¯ä½¿ç”¨\n```python\nfrom openai import OpenAI\n\n# åˆå§‹åŒ–å®¢æˆ·ç«¯\nclient = OpenAI(\n    base_url='http://localhost:7000/v1',\n    api_key='dummy-key'  # ä»»æ„å­—ç¬¦ä¸²ï¼Œä¸éªŒè¯\n)\n\n# å‘é€èŠå¤©è¯·æ±‚\nresponse = client.chat.completions.create(\n    model='gemini-pro',\n    messages=[\n        {'role': 'user', 'content': 'Hello!'}\n    ],\n    temperature=0.7,\n    max_tokens=1000\n)\n\n# è·å–å“åº”å†…å®¹\nprint(response.choices[0].message.content)\n```"
        },
        "modified_files": {},
        "deleted_files": []
    }
]
